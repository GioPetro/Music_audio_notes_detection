{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from Preprocess.ipynb\n",
      "Importing Jupyter notebook from Midiz.ipynb\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, Dropout, TimeDistributed, Reshape, Lambda, Input\n",
    "from keras.layers import LSTM, Bidirectional\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "from keras.regularizers import l1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import pretty_midi\n",
    "\n",
    "import nbimporter\n",
    "import import_ipynb\n",
    "import Preprocess, Midiz\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, io\n",
    "import random\n",
    "pretty_midi.pretty_midi.MAX_TICK = 1e30 # Prevents Maximum tick overflow for the midi tracks that are big (normal songs).\n",
    "np.set_printoptions(threshold=np.nan) # print shows all.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "np.set_printoptions(threshold=12000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def training_generator(window):\n",
    "    path = glob.glob('G:\\ΣΧΟΛΗ p12127\\Πτυχιακη\\MAPS Dataset\\Music Dataset\\Train Dataset\\**\\**\\**\\*.wav')\n",
    "    \n",
    "    while True:\n",
    "        selected_file = random.choice(path) #this selects a random file anew.\n",
    "        with open((selected_file),\"r\") as f:\n",
    "            wave_path = str(f)\n",
    "            wave_path = wave_path[25:].split(\"' mode='r'\")[0]\n",
    "            midi_path = wave_path.split('.wav')[0] + '.mid'\n",
    "            \n",
    "            fbanks = Preprocess.process(wave_path, small_window_size=window)\n",
    "            fbanks = fbanks.T\n",
    "            midi_labels = Midiz.piano_roll(midi_path, fbanks.shape[0])\n",
    "            \n",
    "            #get a random start, but 50 frames less than max, because the sample is 50 frames length.\n",
    "            Xtrain = np.empty((32,50,88))\n",
    "            Ytrain = np.empty((32,88))\n",
    "            \n",
    "            # get a random number out of the frames of filterbanks, but 50 frames less than max.\n",
    "            random_index = random.randint(0,fbanks.shape[0]-50)\n",
    "            \n",
    "            #print(\"index chosen: \", random_index)\n",
    "            #print(fbanks[random_index:random_index+50,:], \"\\n\\n LABELS: \\n\\n\")\n",
    "            #print(midi_labels[random_index:random_index+50,:])\n",
    "            \n",
    "            for batch in range(32):\n",
    "                for frame in range(random_index,random_index+50,25):\n",
    "                    Ytrain[batch] = midi_labels[frame+25]\n",
    "                    for i in range(50):\n",
    "                        Xtrain[batch,i] = fbanks[random_index+i]\n",
    "\n",
    "            yield Xtrain, Ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_generator(window):\n",
    "    path = glob.iglob('G:\\ΣΧΟΛΗ p12127\\Πτυχιακη\\MAPS Dataset\\Music Dataset\\Validation Dataset\\**\\**\\**\\*.wav')\n",
    "    \n",
    "    while True:\n",
    "        selected_file = next(path)\n",
    "        #print(selected_file)\n",
    "        with open((selected_file),\"r\") as f:\n",
    "            wave_path = str(f)\n",
    "            wave_path = wave_path[25:].split(\"' mode='r'\")[0]\n",
    "            midi_path = wave_path.split('.wav')[0] + '.mid'\n",
    "            Xvalid = np.empty((32,50,88))\n",
    "            Yvalid = np.empty((32,88))\n",
    "            fbanks = Preprocess.process(wave_path, small_window_size=window)\n",
    "            fbanks = fbanks.T\n",
    "            midi_labels = Midiz.piano_roll(midi_path,fbanks.shape[0])\n",
    "            batches = int(fbanks.shape[0]/(25*32)) # 32batch size, 50 frames BUT we overlap by 25. So slide=25.\n",
    "            #print(batches, \"Batches available.\", fbanks.shape[0], \"Samples\")\n",
    "            for iters in range(batches):\n",
    "                for b in range(32):\n",
    "                    try:\n",
    "                        Yvalid[b,:] = midi_labels[(b+1)*25 + 25*iters]\n",
    "                        #print(\"Yvalid labels: \", b*25+25*iters)\n",
    "                    except IndexError:\n",
    "                        Yvalid[b,:] = midi_labels[-1]\n",
    "                    for i in range(50):\n",
    "                        try:\n",
    "                            Xvalid[b,i]=fbanks[i + 25*b + 32*25*iters]#iterate mult with 25 because of overlapping windows!\n",
    "                        except IndexError:\n",
    "                            Xvalid[b,i]=fbanks[-1]\n",
    "                        #if i==0 :print(i + 25*b + 32*25*iters, b, iters )\n",
    "            yield Xvalid,Yvalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def note_model():\n",
    "    batch_size, frames, banks = 32 ,50, 88\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(100, stateful=False, return_sequences=True,  kernel_regularizer=l1(10**(-4)), dropout=0.5),\n",
    "    batch_size=batch_size,batch_input_shape =(batch_size, frames, banks)))\n",
    "    model.add(Bidirectional(LSTM(100, stateful=False, return_sequences=False,  kernel_regularizer=l1(10**(-4)), dropout=0.5)))\n",
    "    model.add(Dense(88, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (32, 50, 200)             151200    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (32, 200)                 240800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (32, 88)                  17688     \n",
      "=================================================================\n",
      "Total params: 409,688\n",
      "Trainable params: 409,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def train_note_model(model,window):\n",
    "    checkpoint_path = \"12 Oct run\\\\2x100units-loss=BCE-Model-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "    model.compile(optimizer='SGD', loss='binary_crossentropy', metrics=['accuracy']) #mean_squared_error or binary_crossentropy\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=10, verbose=0, mode='min')\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=10, min_lr=0.001)\n",
    "    checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "    model.fit_generator(training_generator(window=window), steps_per_epoch=100, \n",
    "                        callbacks=[monitor, reduce_lr, checkpoint],\n",
    "                        validation_data= validation_generator(window=window), validation_steps=4,\n",
    "                        verbose=1, epochs=10, shuffle=False)\n",
    "    \n",
    "model = note_model()\n",
    "#model = load_model('20 Sept run\\\\100units-loss=MSE-Model-03-0.07.hdf5')\n",
    "#train_note_model(model, window=True)\n",
    "\n",
    "# Continue training with the big window of FFT\n",
    "#train_note_model(model, window=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame  0 =  [0, 10, 13, 49, 56, 80]\n",
      "frame  1 =  [0, 9, 13, 53, 54, 77]\n",
      "frame  2 =  [0, 8, 13, 44, 55, 75]\n",
      "frame  3 =  [1, 7, 9, 39, 58, 77]\n",
      "frame  4 =  [0, 14, 20, 45, 66, 84]\n",
      "frame  5 =  [2, 12, 19, 44, 62, 81]\n",
      "frame  6 =  [1, 7, 15, 41, 61, 78]\n",
      "frame  7 =  [1, 7, 18, 40, 60, 78]\n",
      "frame  8 =  [2, 8, 15, 42, 57, 78]\n",
      "frame  9 =  [2, 8, 20, 38, 58, 80]\n",
      "frame  10 =  [1, 11, 19, 48, 49, 81]\n",
      "frame  11 =  [1, 11, 17, 45, 49, 85]\n",
      "frame  12 =  [0, 17, 19, 44, 53, 85]\n",
      "frame  13 =  [1, 10, 14, 45, 55, 83]\n",
      "frame  14 =  [1, 9, 12, 48, 54, 81]\n",
      "frame  15 =  [2, 7, 16, 39, 62, 75]\n",
      "frame  16 =  [2, 7, 15, 37, 61, 75]\n",
      "frame  17 =  [1, 10, 11, 37, 60, 78]\n",
      "frame  18 =  [4, 18, 23, 43, 56, 81]\n",
      "frame  19 =  [1, 16, 17, 39, 56, 72]\n",
      "frame  20 =  [1, 8, 13, 40, 57, 76]\n",
      "frame  21 =  [1, 11, 13, 46, 53, 78]\n",
      "frame  22 =  [2, 12, 16, 47, 51, 76]\n",
      "frame  23 =  [2, 11, 13, 43, 56, 75]\n",
      "frame  24 =  [3, 11, 12, 41, 56, 75]\n",
      "frame  25 =  [2, 12, 14, 39, 57, 79]\n",
      "frame  26 =  [1, 8, 11, 36, 60, 76]\n",
      "frame  27 =  [5, 14, 20, 47, 57, 76]\n",
      "frame  28 =  [3, 14, 23, 43, 55, 81]\n",
      "frame  29 =  [1, 10, 16, 39, 57, 73]\n",
      "frame  30 =  [1, 8, 11, 40, 58, 74]\n",
      "frame  31 =  [1, 12, 13, 43, 56, 78]\n"
     ]
    }
   ],
   "source": [
    "'''make function where prints Ypred/Ytruth in a for loop using the 32batches.'''\n",
    "#def make_pred(inputfile):\n",
    "    \n",
    "model = load_model('12 Oct run\\\\2x100units-loss=BCE-Model-10-0.96.hdf5')\n",
    "#inputfile = 'G:\\ΣΧΟΛΗ p12127\\Πτυχιακη\\MAPS Dataset\\Test Dataset\\MAPS_AkPnBcht_1\\AkPnBcht\\ISOL\\CH\\MAPS_ISOL_CH0.1_F_AkPnBcht.wav'\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "gen= validation_generator(window=True)\n",
    "x,y = next(gen)\n",
    "#yhat = model.predict_classes(x, batch_size=32, verbose=2)\n",
    "\n",
    "#def make_pred(inputfile,notes=3):\n",
    "'''inputfile= file to predict.\n",
    "notes = number of notes per frame to predict.'''\n",
    "    #make function that creates the frames for the file. similar to the generators.\n",
    "yhat = model.predict(x)\n",
    "indx = np.argsort(yhat)\n",
    "ylist=[]\n",
    "for i in range(yhat.shape[0]):\n",
    "    for j in range(yhat.shape[1]):\n",
    "        if indx[i,j] <= 5: #notes\n",
    "            #print(indx[i,j], \"th note: \", j)\n",
    "            ylist.append(j)\n",
    "    print(\"frame \", i, \"= \", ylist)\n",
    "    ylist[:]=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module Preprocess:\n",
      "\n",
      "NAME\n",
      "    Preprocess\n",
      "\n",
      "FUNCTIONS\n",
      "    create_frames(data, nfft_length, number_of_frames)\n",
      "    \n",
      "    extract(inputfile, small_window_size=True)\n",
      "    \n",
      "    firdif(fb)\n",
      "    \n",
      "    process(inputfile, small_window_size)\n",
      "    \n",
      "    spectrogram(frames, nfft_length, sr)\n",
      "        Hertz vocabulary.\n",
      "    \n",
      "    wave_plot(filterbanks)\n",
      "    \n",
      "    zero_pad(filterbanks)\n",
      "\n",
      "DATA\n",
      "    interact = <ipywidgets.widgets.interaction._InteractFactory object>\n",
      "\n",
      "FILE\n",
      "    c:\\users\\gio\\desktop\\p12127\\jupyter notebook home\\ptuxiakh\\preprocess.ipynb\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train_note_model(model, window=False)\n",
    "help(Preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
